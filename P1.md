# Finding Lane Lines on the Road
## Overview
In this project, I used Python and OpenCV to detect lane lines on the road images and applied it to process some road test videos. I have learnt and applied the following main techniques to this project:
- Color spaces and filter
- Canny Edge detection
- Gaussian Blur
- Region of Interest selection
- Hough transform lines detection
## Lane finding pipeline
In order to process a road image to find lane lines, I implemented the pipeline with 6 steps: filter yellow and white on image, gray scaling, gaussian blue, edges detection, region of interest selection, hough transform detection. After that, I need to modify the draw_line() function by averagating and extraploating lines based on slope and intercept, draw lines on original image.
I showed the output images for each step in order to debug and parameter turning. I can process two first videos not difficulity but there are many difficults on the challenge video. I have tried to capture some challenge images from challenge video and added them to the test images. You can open and run the [source file](https://github.com/HiepTang/CarND-LaneLines-P1/blob/master/P1.ipynb) for more detail and results at each step.               
The following are the detail of each step
### Filter yellow and white colors on image
I assumed that the main colors for lane lines are yellow and white. So in order to reduce the noise on road images, I filtered on image by focusing only on yellow and white colors. I have referenced to [Naoki's article](https://medium.com/towards-data-science/finding-lane-lines-on-the-road-30cf016a1165) for this step.
#### Convert RGB to HLS
```python
ef convert_hls(image):
    """ Converts RGB to HLS"""
    return cv2.cvtColor(image, cv2.COLOR_RGB2HLS)
# Test the convert_hls function
test_hls_images = list(map(convert_hls, test_images))
if debug:
    show_images(test_hls_images)
```
#### Filter yellow and white colors
```python
def filter_white_yellow(image):
    """ Filters image focus only on white and yellow range"""
    converted = convert_hls(image)
   # white color mask
    lower = np.uint8([  0, 200,   0])
    upper = np.uint8([255, 255, 255])
    white_mask = cv2.inRange(converted, lower, upper)
    # yellow color mask
    lower = np.uint8([ 10,   0, 100])
    upper = np.uint8([ 40, 255, 255])
    yellow_mask = cv2.inRange(converted, lower, upper)
    # combine the mask
    mask = cv2.bitwise_or(white_mask, yellow_mask)
    return cv2.bitwise_and(image, image, mask = mask)
    
white_yellow_images = list(map(filter_white_yellow, test_images))
if debug:
    show_images(white_yellow_images)
```
### Gray scaling
In order to detect edges in the images based on the magnitude of piexl intensity changes using Canny edge detection, they will be converted to gray scaled. This step converts the yellow and white images into gray scale for edge detection.
```python
def grayscale(img):
    """Applies the Grayscale transform
    This will return an image with only one color channel
    but NOTE: to see the returned image as grayscale
    (assuming your grayscaled image is called 'gray')
    you should call plt.imshow(gray, cmap='gray')"""
    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)

# Show the gray test images
gray_images = list(map(grayscale, white_yellow_images))
if debug:
    show_images(gray_images)
```
### Gaussian Blur
This step makes the edges become smoother using cv2.GaussianBlur() function.This function requires the kernel size parameter. I have tried with 1, 3, 5, 7, 9, 11, 13, 15 and 17 (odd values) kernel size and finnaly with 13 because it's good enough. Some edges are lost on the challenge images from challenge video with the kernel size 17.
```python
def gaussian_blur(img, kernel_size):
    """Applies a Gaussian Noise kernel"""
    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)
    
kernel_size = 13
blur_images = list(map(lambda gray: gaussian_blur(gray, kernel_size), gray_images))
if debug:
    show_images(blur_images)
```
### Detect edges with canny
After filtered yellow and white and gray scaled, the images will be detected edges using the cv2.Canny() function. I have tried to apply some high thresold and low thresold parameters following the upper:lower ration as 3:1 as Canny recommendation. Finnally, the 150:50 is working fine with me.
```python
def canny(img, low_threshold, high_threshold):
    """Applies the Canny transform"""
    return cv2.Canny(img, low_threshold, high_threshold)
# Detect edges with canny
low_thresold = 50
high_thresold = 150
edges_images = list(map(lambda blur:canny(blur, low_thresold, high_thresold), blur_images))
if debug:
    show_images(edges_images)
```
### Select region of interest
I need to focus on a speacial region that have lane lines and skip the other such as the sky, the other cars. First of all, I have tried with a hard code region and it works fine with test images. However, I had stucks with images from video because they have a bigger size than test images (1280 x 720 compares with 960 x 540), so I chose vertices based on image size for more flexible.
``` python
# define the region of interest vertices based on image size
def calculate_roi(img):
    rows, cols = img.shape[:2]
    p1 = [cols*0.1, rows*0.95]
    p2 = [cols*0.4, rows*0.6]
    p3 = [cols*0.6, rows*0.6] 
    p4 = [cols*0.9, rows*0.95]
    vertices = np.array([[p1, p2, p3, p4]], dtype=np.int32)
    return vertices
    
 def region_of_interest(img, vertices):
    """
    Applies an image mask.
    
    Only keeps the region of the image defined by the polygon
    formed from `vertices`. The rest of the image is set to black.
    """
    #defining a blank mask to start with
    mask = np.zeros_like(img)   
    
    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image
    if len(img.shape) > 2:
        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image
        ignore_mask_color = (255,) * channel_count
    else:
        ignore_mask_color = 255
        
    #filling pixels inside the polygon defined by "vertices" with the fill color    
    cv2.fillPoly(mask, vertices, ignore_mask_color)
    
    #returning the image only where mask pixels are nonzero
    masked_image = cv2.bitwise_and(img, mask)
    return masked_image   

# filter region of interest
# define the vertices following image size for more flexible.
roi_images = list(map(lambda edges: region_of_interest(edges, calculate_roi(edges)), edges_images))
if debug:
    show_images(roi_images)
```
### Hough transform lines detection
This step uses the cv2.HoughLinesP function to detect the lines in the edge images. It's very difficult to me for choosing the optimization parameter for this function. I have played with many options in order to get the good parameters for detecting the lines clearly.
```python
def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):
    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)
    return lines

rho = 1
theta = np.pi/180
threshold = 15
min_line_len = 15
max_line_gap = 280
# Hough transform lines
list_of_lines = list(map(lambda roi_image:hough_lines(roi_image, rho, theta, threshold, min_line_len, max_line_gap), roi_images))

list_lines = []
# hough line images
for lines, img in zip(list_of_lines, roi_images):
    list_lines.append(hough_lines_image(img, lines))
line_images = []
# weight lines to original images
for lines, img in zip(list_lines, test_images):
    line_images.append(weighted_img(lines, img, 0.8, 1, 0))
if debug:
    show_images(line_images)
```
### Average and extrapolate lines
After the hough transform lines detection, the lines are detected on road images now. However, these lines are not connected and expanded fully on image. This step tried to average and extrapolate these lines together based on slope and intercept. The left lane should have a negative slope, and the right lane should have a positive slope. I have modified the draw_lines() function to draw lane line clearly.
```python
# average and extrapolate lines
# based on slope, try to get the left lane and right lane
# vertical line will be ignore
def average_lines(lines):
    left_lines = []
    left_weights = []
    right_lines = []
    right_weights = []
    if lines is None:
        return None
    for line in lines:
        for x1,y1,x2,y2 in line:
            if x1==x2:
                continue # ignore vertical line
            slope = (y2-y1)/(x2-x1)
            intercept = y1 - x1 * slope
            length = np.sqrt((y2-y1)**2 + (x2-x1)**2)
            if slope < 0:
                left_lines.append((slope, intercept))
                left_weights.append((length))
            else:
                right_lines.append((slope, intercept))
                right_weights.append((length))
    left_lane = []
    if len(left_weights) > 0:
        left_lane = np.dot(left_weights, left_lines) / np.sum(left_weights)
    right_lane = []
    if len(right_weights) > 0:
        right_lane = np.dot(right_weights, right_lines) / np.sum(right_weights)
    return left_lane, right_lane
    
def lane_lines(img, lines):
    left_lane, right_lane = average_lines(lines)
    # convert to line pixels
    y1 = img.shape[0]
    y2 = y1 * 0.6
    
    
    
    left_line = convert_line_pixels(y1, y2, left_lane)
    right_line = convert_line_pixels(y1, y2, right_lane)
    return left_line, right_line
    
def draw_lines(img, lines, color=[255, 0, 0], thickness=14):
    if lines is None:
        return None
    
    lanes = lane_lines(img, lines)
    line_image = np.zeros_like(img)
    
    for lane in lanes:
        cv2.line(line_image, *lane, color, thickness)
    
    return weighted_img(line_image, img)
lane_images = []

for img, lines in zip(test_images, list_of_lines):
    lane_images.append(draw_lines(img, lines))
if debug:
    show_images(lane_images)
```
### Putting everything together for processing one image function
Every steps run fine and we have the optimization parameters. Now this time to put everything together to implement a function to process one image through all pipelines.
```python
def draw_laneline(img):
    yellow_white = filter_white_yellow(img)
    gray = grayscale(yellow_white)
    blur_gray = gaussian_blur(gray, kernel_size)
    edges = canny(blur_gray, low_thresold, high_thresold)
    marked_edges = region_of_interest(edges, calculate_roi(edges))
    lines = hough_lines(marked_edges, rho, theta, threshold, min_line_len, max_line_gap)    
    combo = draw_lines(img, lines)
    return combo
# Test with test images
test_images_output = list(map(draw_laneline, test_images))
if debug:
    show_images(test_images_output)
```
## Video Clip
After implement to work fine on test images, I have tried to apply it to process the testing videos. At the first time, I have some stuffs because of the size of image from video is bigger than the size of test image. I need to choose the region of interest based on image size instead of the hard code. I also had a big problem with the challenge video. I have tried to capture some images from the challenge video and putted them to test images for parameter turning. I found a solution by applied the yellow and white filtering and changed the cv2.HoughLinesP() parameters function. Finnally, it can work with 3 test videos with some limitation with the curved, the up/down hill.
## Conclusion
The project was successful with the processed test videos that showed the clearly lines are detected and smooth handled.
It works fine with the straight lane lines. However, it cannot draw the lines fully with the curved lanes. I think I need to apply the other techniques to handle it such as polyfit and horizontal line detection.
I think it is just a basic lane finding solution and it has so many limitaton such as weather, the light, the car in front of, etc... And we should have the other approach to solve this problem better such as deep learning.
